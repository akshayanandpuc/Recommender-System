{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Association Rules – AR. \n",
    "To assess the strength of simple two-element co-occurrence patterns, we included a method named AR which can be considered as an association rule technique with a maximum rule size of two. Technically, we create a rule r(p,q) for every two items 'p' and 'q' that appear together in the training sessions. We determine the weight, w(p,q), of each rule simply as the number of times p and q appear together in past sessions. Given the current session 's', the AR score of a target item 'i' will be then computed as   **score_ar(i,s) = w(i,j) × 1_AR(r(i,j))** where 'j' is the last item of the current session 's' for which we want to predict the successor and AR is the set of rules and their weights as determined based on the training data. The indicator function 1_AR(ri,j) = 1 when AR contains r(i,j) and 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Simple Sequential Rules – SR\n",
    " The sr method is a variant of AR, which aims to take the order of the events into account. Similar to the AR method, we create a sequential rule for the co-occurrence of every two items 'p' and 'q' as r(p,q) in the training data. This time, however, we consider the distance between 'p' and 'q' in the session when computing the weight of the rules. In our implementation, we use the multiplicative inverse as a weight function and set w(p,q) = 1/x, where 'x' is the number of items that appear between 'p'\n",
    "and 'q' in a session. Other heuristics such as a linear or a logarithmic function can also be used. In case that those two items appear together in another session in the training data, the weight of the rule in that session will be added to the current weight. We finally normalize the weight and divide it by the total number of sessions that contributed to the weight. Given the current session 's', the SR score of a target item i is then computed as **score_sr(i,s) = w(j,i) × 1SR(r(j,i))** where 'j' is the last item of session 's' and SR is the set of sequential rules. The indicator function 1SR(r(j,i)) = 1 when SR contains r(j,i) and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import dateutil.parser\n",
    "from scipy.sparse import csr_matrix\n",
    "import operator\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation, cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "b'Skipping line 2120260: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 2446318: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11141081: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11152099: expected 6 fields, saw 12\\nSkipping line 11152402: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11882087: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 12902539: expected 6 fields, saw 8\\nSkipping line 12935044: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 17589539: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "df_hist = pd.read_table('userid-timestamp-artid-artname-traid-traname.tsv', error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist.columns = ['userid', 'timestamp', 'artistid','artistname','trackid','trackname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_profile = pd.read_table('userid-profile.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df_profile['#id'].tolist()[:100]\n",
    "\n",
    "df_hist = df_hist[df_hist['userid'].isin(user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist['timestamp'] = df_hist['timestamp'].apply(lambda x : dateutil.parser.parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist.sort_values(by=['userid','timestamp'], inplace=True)\n",
    "cond1 = df_hist.timestamp-df_hist.timestamp.shift(1) > pd.Timedelta(5, 'm')\n",
    "cond2 = df_hist.userid != df_hist.userid.shift(1)\n",
    "df_hist['sessionid'] = (cond1|cond2).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionid</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>191986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>226631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>194672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>124560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>216761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionid  track_id\n",
       "0          0    191986\n",
       "1          0    226631\n",
       "2          1    194672\n",
       "3          2    124560\n",
       "4          2    216761"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist['track_id'] = df_hist['trackname'].astype(\"category\").cat.codes\n",
    "track_lookup = df_hist[['track_id', 'trackname','artistname']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist.drop(['userid','timestamp','artistid','artistname','trackid','trackname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist['sessionid'] = df_hist['sessionid'].apply(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = df_hist.sessionid.unique().tolist()\n",
    "sessn_past = {}\n",
    "for ssn in session:\n",
    "    sessn_past[ssn] = []\n",
    "for row in df_hist.itertuples():\n",
    "    sessn_past[row.sessionid].append(row.track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks  = df_hist.track_id.unique().tolist()\n",
    "track_past = {}\n",
    "for track in all_tracks:\n",
    "    track_past[track] = []\n",
    "for key,value in sessn_past.items():\n",
    "    for track in value:\n",
    "        if key not in track_past[track]:\n",
    "            track_past[track].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:0  Song_index:0  Track_index:1  weight:1\n",
      "Session:390  Song_index:0  Track_index:1  weight:1\n",
      "Session:427  Song_index:0  Track_index:1  weight:1\n",
      "Session:6059  Song_index:3  Track_index:4  weight:1\n",
      "Session:495  Song_index:3  Track_index:4  weight:1\n",
      "Session:241  Song_index:0  Track_index:1  weight:1\n",
      "Session:1078  Song_index:0  Track_index:1  weight:1\n",
      "Session:1273  Song_index:1  Track_index:2  weight:1\n",
      "Session:766  Song_index:1  Track_index:2  weight:1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "song_id = 191987\n",
    "t_id = 226632\n",
    "past = track_past[song_id]\n",
    "t_past = track_past[t_id]\n",
    "common = list(set(past) & set(t_past))\n",
    "if len(common)>0:\n",
    "    wt = 0\n",
    "    for ssn in common:\n",
    "        hist = sessn_past[ssn]\n",
    "        idx_song = hist.index(song_id)\n",
    "        idx_t = hist.index(t_id)\n",
    "        diff = abs(idx_song - idx_t)\n",
    "        wt+=diff\n",
    "        print(\"Session:{0}  Song_index:{1}  Track_index:{2}  weight:{3}\".format(ssn,idx_song,idx_t,diff))\n",
    "    normalized_wt = wt/len(common)\n",
    "print(normalized_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-f864fe647f22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0msong\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0ms_past\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack_past\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msong\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mcommon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_past\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_past\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mwt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "track_a = [] \n",
    "track_b = []\n",
    "weight = []\n",
    "for track in all_tracks:\n",
    "    t_past = track_past[track]\n",
    "    for song in all_tracks:\n",
    "        if track!=song:\n",
    "            s_past = track_past[song]\n",
    "            common = list(set(t_past) & set(s_past))\n",
    "            if len(common) > 0:\n",
    "                wt = 0\n",
    "                for ssn in common:\n",
    "                    hist = sessn_past[ssn]\n",
    "                    idx_t = hist.index(track)\n",
    "                    idx_s = hist.index(song)\n",
    "                    diff = abs(idx_t - idx_s)\n",
    "                    wt+=diff\n",
    "                normalized_wt = wt/len(common)\n",
    "                track_a.append(track)\n",
    "                track_b.append(song)\n",
    "                weight.append(normalized_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Launching Of Big Face'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_lookup[track_lookup.track_id==191987]['trackname'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrecommendation(sessionid):\n",
    "    last_track_id = sessn_past[sessionid][-1]\n",
    "    track = []\n",
    "    weight = []\n",
    "    t_past = track_past[last_track_id]\n",
    "    for song in all_tracks:\n",
    "        if last_track_id!=song:\n",
    "            s_past = track_past[song]\n",
    "            common = list(set(t_past) & set(s_past))\n",
    "            if len(common) > 0:\n",
    "                wt = 0\n",
    "                for ssn in common:\n",
    "                    hist = sessn_past[ssn]\n",
    "                    idx_t = hist.index(last_track_id)\n",
    "                    idx_s = hist.index(song)\n",
    "                    diff = abs(idx_t - idx_s)\n",
    "                    wt+=diff\n",
    "                normalized_wt = wt/len(common)\n",
    "                track.append(song)\n",
    "                weight.append(normalized_wt)\n",
    "    track,weight = zip(*sorted(zip(track,weight)))\n",
    "    track = track[::-1]\n",
    "    weight = weight[::-1]\n",
    "    print(\"Last track listened to was: \")\n",
    "    print(\"Track id:{0}  Track Name:{1}\".format(last_track_id,track_lookup[track_lookup.track_id==last_track_id]['trackname'].tolist()[0]))\n",
    "    print(\"Recommended songs are:\")\n",
    "    for i in range(len(track)):\n",
    "        print(\"Track id:{0}  Track Name:{1}\".format(track[i],track_lookup[track_lookup.track_id==track[i]]['trackname'].tolist()[0]))\n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last track listened to was: \n",
      "Track id:226632  Track Name:Zn Zero\n",
      "Recommended songs are:\n",
      "Track id:226202  Track Name:Zala\n",
      "Track id:206385  Track Name:Twin Home\n",
      "Track id:191987  Track Name:The Launching Of Big Face\n",
      "Track id:169730  Track Name:Sleep Warm\n",
      "Track id:162624  Track Name:Scum\n",
      "Track id:138752  Track Name:Omstart\n",
      "Track id:128127  Track Name:Music\n",
      "Track id:111880  Track Name:Like A Rolling Stone\n",
      "Track id:87062  Track Name:I Citizen The Loathsome\n",
      "Track id:77155  Track Name:Gum\n",
      "Track id:36676  Track Name:Chin Hippy\n",
      "Track id:29692  Track Name:Breezin'\n",
      "Track id:22371  Track Name:Beep It\n",
      "Track id:14606  Track Name:Anirog D9\n"
     ]
    }
   ],
   "source": [
    "rec_tracks = getrecommendation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these recommended  songs are from same artists which is pretty intuitive as people tend to listen to songs from same artists in a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
